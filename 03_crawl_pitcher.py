"""
KBO ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ 2024 / 2025 ì‹œì¦Œ SSG ëœë”ìŠ¤ íˆ¬ìˆ˜ ê¸°ë¡ ìˆ˜ì§‘
playwrightë¥¼ ì´ìš©í•œ í¬ë¡¤ë§ ì½”ë“œ

ì‹¤í–‰ ë°©ë²•:
    python 03_crawl_pitcher.py
"""

import asyncio
import os
import pandas as pd
from playwright.async_api import async_playwright


BASE_URL = "https://www.koreabaseball.com/Record/Player/PitcherBasic/Basic1.aspx"
YEARS    = ["2024", "2025"]
TEAM     = "SSG"


def parse_ip(ip_str: str) -> float:
    """'180 2/3' â†’ 180.67 í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    ip_str = str(ip_str).strip()
    if ' ' in ip_str:
        parts = ip_str.split()
        whole = float(parts[0])
        frac_map = {'1/3': 0.33, '2/3': 0.67}
        return whole + frac_map.get(parts[1], 0)
    return float(ip_str) if ip_str else 0.0


async def select_filters(page, year: str):
    """ì—°ë„, íŒ€ í•„í„° ì„ íƒ"""
    await page.select_option('select:nth-of-type(1)', year)
    await page.wait_for_timeout(800)
    await page.select_option('select:nth-of-type(3)', TEAM)
    await page.wait_for_timeout(1000)


async def parse_table(page, year: str) -> list[dict]:
    """í˜„ì¬ í˜ì´ì§€ íˆ¬ìˆ˜ ê¸°ë¡ íŒŒì‹±"""
    rows = await page.query_selector_all('table tbody tr')
    records = []

    for row in rows:
        cells = await row.query_selector_all('td')
        if len(cells) < 18:
            continue

        texts = [await c.inner_text() for c in cells]
        records.append({
            'season': year,
            'ì„ ìˆ˜ëª…': texts[1].strip(),
            'íŒ€':     texts[2].strip(),
            'ERA':    texts[3].strip(),
            'G':      texts[4].strip(),
            'W':      texts[5].strip(),
            'L':      texts[6].strip(),
            'SV':     texts[7].strip(),
            'HLD':    texts[8].strip(),
            'WPCT':   texts[9].strip(),
            'IP':     texts[10].strip(),
            'H':      texts[11].strip(),
            'HR':     texts[12].strip(),
            'BB':     texts[13].strip(),
            'HBP':    texts[14].strip(),
            'SO':     texts[15].strip(),
            'R':      texts[16].strip(),
            'ER':     texts[17].strip(),
            'WHIP':   texts[18].strip() if len(texts) > 18 else '',
        })

    return records


async def crawl_all_pages(page, year: str) -> list[dict]:
    """ì „ì²´ í˜ì´ì§€ ìˆœíšŒ (ìµœëŒ€ 5í˜ì´ì§€)"""
    records = await parse_table(page, year)

    for page_num in range(2, 6):
        btn = await page.query_selector(f'a[href*="btnNo{page_num}"]')
        if not btn:
            break
        await btn.click()
        await page.wait_for_timeout(1200)
        new_records = await parse_table(page, year)
        if not new_records:
            break
        records += new_records

    return records


async def crawl_season(browser, year: str) -> pd.DataFrame:
    """íŠ¹ì • ì‹œì¦Œ íˆ¬ìˆ˜ ë°ì´í„° ìˆ˜ì§‘"""
    page = await browser.new_page()
    print(f"\n[{year}] íˆ¬ìˆ˜ ê¸°ë¡ ìˆ˜ì§‘ ì¤‘...")
    await page.goto(BASE_URL, wait_until="domcontentloaded")
    await page.wait_for_timeout(1000)

    await select_filters(page, year)
    records = await crawl_all_pages(page, year)
    await page.close()

    df = pd.DataFrame(records)
    df = df[df['íŒ€'] == 'SSG'].reset_index(drop=True)

    # ìˆ«ìí˜• ë³€í™˜
    num_cols = ['ERA', 'G', 'W', 'L', 'SV', 'HLD', 'WPCT',
                'H', 'HR', 'BB', 'HBP', 'SO', 'R', 'ER', 'WHIP']
    for col in num_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    # IP ë³€í™˜ ('180 2/3' â†’ 180.67)
    df['IP'] = df['IP'].apply(parse_ip)

    print(f"[{year}] âœ… SSG íˆ¬ìˆ˜ {len(df)}ëª… ìˆ˜ì§‘ ì™„ë£Œ")
    return df


async def main():
    os.makedirs("data", exist_ok=True)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)

        all_dfs = []
        for year in YEARS:
            df = await crawl_season(browser, year)
            df.to_csv(f'data/ssg_pitchers_{year}_raw.csv', index=False, encoding='utf-8-sig')
            all_dfs.append(df)

        await browser.close()

    df_all = pd.concat(all_dfs, ignore_index=True)
    df_all.to_csv('data/ssg_pitchers_all.csv', index=False, encoding='utf-8-sig')

    # ìµœì†Œ ì´ë‹ í•„í„° (ì„ ë°œ: 30ì´ë‹+, ë¶ˆíœ: 15ì´ë‹+)
    df_qualified = df_all[df_all['IP'] >= 15].copy()
    df_qualified.to_csv('data/ssg_pitchers_qualified.csv', index=False, encoding='utf-8-sig')

    print("\n" + "="*50)
    print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
    print("="*50)
    for year in YEARS:
        subset = df_qualified[df_qualified['season'] == int(year)]
        print(f"\nâ–¶ {year} ì‹œì¦Œ (15ì´ë‹ ì´ìƒ: {len(subset)}ëª…)")
        print(subset[['ì„ ìˆ˜ëª…', 'G', 'IP', 'ERA', 'W', 'L', 'SV', 'HLD']].to_string(index=False))

    print("\nğŸ’¾ data/ í´ë”ì— CSV ì €ì¥ ì™„ë£Œ")
    print("  - ssg_pitchers_2024_raw.csv")
    print("  - ssg_pitchers_2025_raw.csv")
    print("  - ssg_pitchers_all.csv")
    print("  - ssg_pitchers_qualified.csv")


if __name__ == "__main__":
    asyncio.run(main())
