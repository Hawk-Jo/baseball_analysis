"""
KBO ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ 2024 / 2025 ì‹œì¦Œ SSG ëœë”ìŠ¤ íƒ€ì ê¸°ë¡ ìˆ˜ì§‘
playwrightë¥¼ ì´ìš©í•œ í¬ë¡¤ë§ ì½”ë“œ

ì‹¤í–‰ ë°©ë²•:
    pip install playwright pandas
    playwright install chromium
    python 01_crawl_kbo.py
"""

import asyncio
import os
import pandas as pd
from playwright.async_api import async_playwright


BASE_URL = "https://www.koreabaseball.com/Record/Player/HitterBasic/Basic1.aspx"
YEARS    = ["2024", "2025"]
TEAM     = "SSG"


async def select_filters(page, year: str):
    """ì—°ë„, íŒ€ í•„í„° ì„ íƒ"""
    await page.select_option('select:nth-of-type(1)', year)
    await page.wait_for_timeout(800)
    await page.select_option('select:nth-of-type(3)', TEAM)
    await page.wait_for_timeout(1000)


async def parse_table(page, year: str) -> list[dict]:
    """í˜„ì¬ í˜ì´ì§€ì˜ íƒ€ì ê¸°ë¡ í…Œì´ë¸” íŒŒì‹±"""
    rows = await page.query_selector_all('table tbody tr')
    records = []

    for row in rows:
        cells = await row.query_selector_all('td')
        if len(cells) < 14:
            continue

        texts = [await c.inner_text() for c in cells]
        records.append({
            'season': year,
            'ì„ ìˆ˜ëª…':  texts[1].strip(),
            'íŒ€':      texts[2].strip(),
            'AVG':     texts[3].strip(),
            'G':       texts[4].strip(),
            'PA':      texts[5].strip(),
            'AB':      texts[6].strip(),
            'R':       texts[7].strip(),
            'H':       texts[8].strip(),
            '2B':      texts[9].strip(),
            '3B':      texts[10].strip(),
            'HR':      texts[11].strip(),
            'TB':      texts[12].strip(),
            'RBI':     texts[13].strip(),
        })

    return records


async def crawl_all_pages(page, year: str) -> list[dict]:
    """ì „ì²´ í˜ì´ì§€ ìˆœíšŒ ìˆ˜ì§‘ (ìµœëŒ€ 5í˜ì´ì§€)"""
    records = await parse_table(page, year)

    for page_num in range(2, 6):
        btn = await page.query_selector(f'a[href*="btnNo{page_num}"]')
        if not btn:
            break
        await btn.click()
        await page.wait_for_timeout(1200)
        new_records = await parse_table(page, year)
        if not new_records:
            break
        records += new_records

    return records


async def crawl_season(browser, year: str) -> pd.DataFrame:
    """íŠ¹ì • ì‹œì¦Œ ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬"""
    page = await browser.new_page()
    print(f"\n[{year}] KBO ì‚¬ì´íŠ¸ ì ‘ì† ì¤‘...")
    await page.goto(BASE_URL, wait_until="domcontentloaded")
    await page.wait_for_timeout(1000)

    print(f"[{year}] í•„í„° ì„¤ì • (íŒ€: {TEAM})...")
    await select_filters(page, year)

    print(f"[{year}] ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    records = await crawl_all_pages(page, year)
    await page.close()

    # DataFrame ë³€í™˜ ë° SSG í•„í„°ë§
    df = pd.DataFrame(records)
    df = df[df['íŒ€'] == 'SSG'].reset_index(drop=True)

    # ìˆ«ìí˜• ë³€í™˜
    num_cols = ['AVG', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'TB', 'RBI']
    for col in num_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')

    print(f"[{year}] âœ… SSG ì„ ìˆ˜ {len(df)}ëª… ìˆ˜ì§‘ ì™„ë£Œ")
    return df


async def main():
    os.makedirs("data", exist_ok=True)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)

        all_dfs = []
        for year in YEARS:
            df = await crawl_season(browser, year)
            df.to_csv(f'data/ssg_hitters_{year}_raw.csv', index=False, encoding='utf-8-sig')
            all_dfs.append(df)

        await browser.close()

    # ë‘ ì‹œì¦Œ í•©ì¹˜ê¸°
    df_all = pd.concat(all_dfs, ignore_index=True)
    df_all.to_csv('data/ssg_hitters_all.csv', index=False, encoding='utf-8-sig')

    # 200íƒ€ì„ ì´ìƒ í•„í„°
    df_qualified = df_all[df_all['PA'] >= 200].copy()
    df_qualified.to_csv('data/ssg_hitters_qualified.csv', index=False, encoding='utf-8-sig')

    print("\n" + "="*50)
    print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
    print("="*50)
    for year in YEARS:
        subset = df_qualified[df_qualified['season'] == year]
        print(f"\nâ–¶ {year} ì‹œì¦Œ (200íƒ€ì„ ì´ìƒ: {len(subset)}ëª…)")
        print(subset[['ì„ ìˆ˜ëª…', 'G', 'PA', 'AVG', 'HR', 'RBI']].to_string(index=False))

    print("\nğŸ’¾ data/ í´ë”ì— CSV ì €ì¥ ì™„ë£Œ")
    print("  - ssg_hitters_2024_raw.csv")
    print("  - ssg_hitters_2025_raw.csv")
    print("  - ssg_hitters_all.csv")
    print("  - ssg_hitters_qualified.csv")


if __name__ == "__main__":
    asyncio.run(main())
